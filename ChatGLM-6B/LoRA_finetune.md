# „ÄêÂÖ≥‰∫é ChatGLM + LoRA ËøõË°åfinetune „ÄëÈÇ£‰∫õ‰Ω†‰∏çÁü•ÈÅìÁöÑ‰∫ã

## „ÄêLLMs ÂÖ•Èó®ÂÆûÊàòÁ≥ªÂàó„Äë

### Á¨¨‰∏ÄÂ±Ç ChatGLM-6B

1. [„ÄêChatGLM-6BÂÖ•Èó®-‰∏Ä„ÄëÊ∏ÖÂçéÂ§ßÂ≠¶ÂºÄÊ∫ê‰∏≠ÊñáÁâàChatGLM-6BÊ®°ÂûãÂ≠¶‰π†‰∏éÂÆûÊàò](ChatGLM-6B/induction.md)
   1. ‰ªãÁªçÔºöChatGLM-6B ÁéØÂ¢ÉÈÖçÁΩÆ Âíå ÈÉ®ÁΩ≤
2. [„ÄêChatGLM-6BÂÖ•Èó®-‰∫å„ÄëÊ∏ÖÂçéÂ§ßÂ≠¶ÂºÄÊ∫ê‰∏≠ÊñáÁâàChatGLM-6BÊ®°ÂûãÂæÆË∞ÉÂÆûÊàò](ChatGLM-6B/ptuning.md)
   1. ChatGLM-6B P-Tuning V2 ÂæÆË∞ÉÔºöFine-tuning the prefix encoder of the model.
3. [„ÄêChatGLM-6BÂÖ•Èó®-‰∏â„ÄëChatGLM ÁâπÂÆö‰ªªÂä°ÂæÆË∞ÉÂÆûÊàò](https://articles.zsxq.com/id_3b42ukjdkwpt.html)
4. [„ÄêChatGLM-6BÂÖ•Èó®-Âõõ„ÄëChatGLM + LoRA ËøõË°åfinetune](https://articles.zsxq.com/id_e2389qm0w0sx.html)
   1. ‰ªãÁªçÔºöChatGLM-6B LoRA ÂæÆË∞ÉÔºöFine-tuning the low-rank adapters of the model.
5. [ChatGLM-6B Â∞èÁºñÂ°´ÂùëËÆ∞](https://articles.zsxq.com/id_fw7vn0mhdsnq.html)
   1. ‰ªãÁªçÔºöChatGLM-6B Âú® ÈÉ®ÁΩ≤ÂíåÂæÆË∞É ËøáÁ®ã‰∏≠ ‰ºöÈÅáÂà∞ÂæàÂ§öÂùëÔºåÂ∞èÁºñÊéâÂùë‰∫ÜÂæàÂ§öÊ¨°Ôºå‰∏∫Èò≤Ê≠¢ Âêé‰∫∫ÂíåÂ∞èÁºñ‰∏ÄÊ†∑ÁªßÁª≠ÊéâÂùëÔºåÂ∞èÁºñÁ¥¢ÊÄßÊääÈÅáÂà∞ÁöÑÂùëÈÉΩÂ°´‰∫Ü„ÄÇ
6. [„ÄêLLMsÂ≠¶‰π†„ÄëÂÖ≥‰∫éÂ§ßÊ®°ÂûãÂÆûË∑µÁöÑ‰∏Ä‰∫õÊÄªÁªì](https://articles.zsxq.com/id_il58nxrs9jxr.html)
7. [„ÄêLLMs ÂÖ•Èó®ÂÆûÊàò ‚Äî‚Äî ÂçÅ‰∏Ä „ÄëÂü∫‰∫é ü§óPEFT ÁöÑÈ´òÊïà ü§ñChatGLM-6B ÂæÆË∞É](https://articles.zsxq.com/id_7rz5jtfguuc5.html)
   1. ÂæÆË∞ÉÊñπÂºèÔºö
      1. ChatGLM-6B Freeze ÂæÆË∞ÉÔºöFine-tuning the MLPs in the last n blocks of the model.
      2. ChatGLM-6B P-Tuning V2 ÂæÆË∞ÉÔºöFine-tuning the prefix encoder of the model.
      3. ChatGLM-6B LoRA ÂæÆË∞ÉÔºöFine-tuning the low-rank adapters of the model.
8. [„ÄêLLMs ÂÖ•Èó®ÂÆûÊàò ‚Äî‚Äî ÂçÅ‰∫å „ÄëÂü∫‰∫é Êú¨Âú∞Áü•ËØÜÂ∫ì ÁöÑÈ´òÊïà ü§ñlangchain-ChatGLM ](https://articles.zsxq.com/id_54vjwns5t6in.html)
   1. ‰ªãÁªçÔºölangchain-ChatGLMÊòØ‰∏Ä‰∏™Âü∫‰∫éÊú¨Âú∞Áü•ËØÜÁöÑÈóÆÁ≠îÊú∫Âô®‰∫∫Ôºå‰ΩøÁî®ËÄÖÂèØ‰ª•Ëá™Áî±ÈÖçÁΩÆÊú¨Âú∞Áü•ËØÜÔºåÁî®Êà∑ÈóÆÈ¢òÁöÑÁ≠îÊ°à‰πüÊòØÂü∫‰∫éÊú¨Âú∞Áü•ËØÜÁîüÊàêÁöÑ„ÄÇ

### Á¨¨‰∫åÂ±Ç Stanford Alpaca 7B 

- [„ÄêLLMs ÂÖ•Èó®ÂÆûÊàò ‚Äî‚Äî ‰∫î „ÄëStanford Alpaca 7B Ê®°ÂûãÂ≠¶‰π†‰∏éÂÆûÊàò](https://articles.zsxq.com/id_xnt3fvp2wxz0.html)
  - ‰ªãÁªçÔºöÊú¨ÊïôÁ®ãÊèê‰æõ‰∫ÜÂØπLLaMAÊ®°ÂûãËøõË°åÂæÆË∞ÉÁöÑÂªâ‰ª∑‰∫≤Ê∞ë LLMs Â≠¶‰π†ÂíåÂæÆË∞É ÊñπÂºèÔºå‰∏ªË¶Å‰ªãÁªçÂØπ‰∫é Stanford Alpaca 7B Ê®°ÂûãÂú®ÁâπÂÆö‰ªªÂä°‰∏ä ÁöÑ ÂæÆË∞ÉÂÆûÈ™åÔºåÊâÄÁî®ÁöÑÊï∞ÊçÆ‰∏∫OpenAIÊèê‰æõÁöÑGPTÊ®°ÂûãAPIÁîüÊàêË¥®ÈáèËæÉÈ´òÁöÑÊåá‰ª§Êï∞ÊçÆÔºà‰ªÖ52kÔºâ„ÄÇ

### Á¨¨‰∏âÂ±Ç Chinese-LLaMA-Alpaca 

- [„ÄêLLMs ÂÖ•Èó®ÂÆûÊàò ‚Äî‚Äî ÂÖ≠ „ÄëChinese-LLaMA-Alpaca Ê®°ÂûãÂ≠¶‰π†‰∏éÂÆûÊàò](https://articles.zsxq.com/id_dqvusswrdg6c.html)
  - ‰ªãÁªçÔºöÊú¨ÊïôÁ®ã‰∏ªË¶Å‰ªãÁªç‰∫Ü Chinese-ChatLLaMA,Êèê‰æõ‰∏≠ÊñáÂØπËØùÊ®°Âûã ChatLLama „ÄÅ‰∏≠ÊñáÂü∫Á°ÄÊ®°Âûã LLaMA-zh ÂèäÂÖ∂ËÆ≠ÁªÉÊï∞ÊçÆ„ÄÇ Ê®°ÂûãÂü∫‰∫é TencentPretrain Â§öÊ®°ÊÄÅÈ¢ÑËÆ≠ÁªÉÊ°ÜÊû∂ÊûÑÂª∫

### Á¨¨ÂõõÂ±Ç Â∞èÁæäÈ©º Vicuna

- [„ÄêLLMs ÂÖ•Èó®ÂÆûÊàò ‚Äî‚Äî ‰∏É „ÄëÂ∞èÁæäÈ©º VicunaÊ®°ÂûãÂ≠¶‰π†‰∏éÂÆûÊàò](https://articles.zsxq.com/id_q9mx24q9fdab.html)
  - ‰ªãÁªçÔºöUC‰ºØÂÖãÂà©Â≠¶ËÄÖËÅîÊâãCMU„ÄÅÊñØÂù¶Á¶èÁ≠âÔºåÂÜçÊ¨°Êé®Âá∫‰∏Ä‰∏™ÂÖ®Êñ∞Ê®°Âûã70‰∫ø/130‰∫øÂèÇÊï∞ÁöÑVicunaÔºå‰øóÁß∞„ÄåÂ∞èÁæäÈ©º„ÄçÔºàÈ™ÜÈ©¨Ôºâ„ÄÇÂ∞èÁæäÈ©ºÂè∑Áß∞ËÉΩËææÂà∞GPT-4ÁöÑ90%ÊÄßËÉΩ

### Á¨¨‰∫îÂ±Ç MiniGPT-4 

- [„ÄêLLMs ÂÖ•Èó®ÂÆûÊàò ‚Äî‚Äî ÂÖ´ „ÄëMiniGPT-4 Ê®°ÂûãÂ≠¶‰π†‰∏éÂÆûÊàò](https://articles.zsxq.com/id_ff0w6czthq25.html)
  - ‰ªãÁªçÔºö MiniGPT-4ÔºåÊòØÊù•Ëá™ÈòøÂçúÊùúÊãâÂõΩÁéãÁßëÊäÄÂ§ßÂ≠¶ÁöÑÂá†‰ΩçÂçöÂ£´ÂÅöÁöÑÔºåÂÆÉËÉΩÊèê‰æõÁ±ª‰ºº GPT-4 ÁöÑÂõæÂÉèÁêÜËß£‰∏éÂØπËØùËÉΩÂäõ

### Á¨¨ÂÖ≠Â±Ç GPT4ALL

- [„ÄêLLMs ÂÖ•Èó®ÂÆûÊàò ‚Äî‚Äî ÂÖ´ „ÄëGPT4ALL Ê®°ÂûãÂ≠¶‰π†‰∏éÂÆûÊàò](https://articles.zsxq.com/id_ff0w6czthq25.html)
  - ‰ªãÁªçÔºö‰∏Ä‰∏™ ÂèØ‰ª•Âú®Ëá™Â∑±Á¨îËÆ∞Êú¨‰∏äÈù¢Ë∑ëËµ∑Êù•ÁöÑ  Nomic AI ÁöÑÂä©ÊâãÂºèËÅäÂ§©Êú∫Âô®‰∫∫ÔºåÊàê‰∏∫Ë¥´Ê∞ëÂÆ∂Â≠©Â≠êÁöÑ Á¶èÈü≥ÔºÅ

### Á¨¨‰∏ÉÂ±Ç AutoGPT

- [AutoGPT ‰ΩøÁî®ÂíåÈÉ®ÁΩ≤](https://articles.zsxq.com/id_pli0z9916126.html)
  - ‰ªãÁªçÔºöAuto-GPTÊòØ‰∏Ä‰∏™Âü∫‰∫éChatGPTÁöÑÂ∑•ÂÖ∑Ôºå‰ªñËÉΩÂ∏Æ‰Ω†Ëá™Âä®ÂÆåÊàêÂêÑÁßç‰ªªÂä°ÔºåÊØîÂ¶ÇÂÜô‰ª£Á†Å„ÄÅÂÜôÊä•Âëä„ÄÅÂÅöË∞ÉÁ†îÁ≠âÁ≠â„ÄÇ‰ΩøÁî®ÂÆÉÊó∂Ôºå‰Ω†Âè™ÈúÄË¶ÅÂëäËØâ‰ªñË¶ÅÊâÆÊºîÁöÑËßíËâ≤ÂíåË¶ÅÂÆûÁé∞ÁöÑÁõÆÊ†áÔºåÁÑ∂Âêé‰ªñÂ∞±‰ºöÂà©Áî®ChatGPTÂíåË∞∑Ê≠åÊêúÁ¥¢Á≠âÂ∑•ÂÖ∑Ôºå‰∏çÊñ≠‚ÄúÊÄùËÄÉ‚ÄùÂ¶Ç‰ΩïÊé•ËøëÁõÆÊ†áÂπ∂ÊâßË°åÔºå‰Ω†ÁîöËá≥ÂèØ‰ª•ÁúãÂà∞‰ªñÁöÑÊÄùËÄÉËøáÁ®ã„ÄÇ

### Á¨¨ÂÖ´Â±Ç MOSS

- [„ÄêLLMs ÂÖ•Èó®ÂÆûÊàò ‚Äî‚Äî ÂçÅ‰∏â „ÄëMOSS Ê®°ÂûãÂ≠¶‰π†‰∏éÂÆûÊàò](https://articles.zsxq.com/id_4vwpxod23zrc.html)
  - ‰ªãÁªçÔºöMOSSÊòØ‰∏Ä‰∏™ÊîØÊåÅ‰∏≠Ëã±ÂèåËØ≠ÂíåÂ§öÁßçÊèí‰ª∂ÁöÑÂºÄÊ∫êÂØπËØùËØ≠Ë®ÄÊ®°ÂûãÔºåmoss-moonÁ≥ªÂàóÊ®°ÂûãÂÖ∑Êúâ160‰∫øÂèÇÊï∞ÔºåÂú®FP16Á≤æÂ∫¶‰∏ãÂèØÂú®ÂçïÂº†A100/A800Êàñ‰∏§Âº†3090ÊòæÂç°ËøêË°åÔºåÂú®INT4/8Á≤æÂ∫¶‰∏ãÂèØÂú®ÂçïÂº†3090ÊòæÂç°ËøêË°å„ÄÇMOSSÂü∫Â∫ßËØ≠Ë®ÄÊ®°ÂûãÂú®Á∫¶‰∏ÉÂçÉ‰∫ø‰∏≠Ëã±Êñá‰ª•Âèä‰ª£Á†ÅÂçïËØç‰∏äÈ¢ÑËÆ≠ÁªÉÂæóÂà∞ÔºåÂêéÁª≠ÁªèËøáÂØπËØùÊåá‰ª§ÂæÆË∞É„ÄÅÊèí‰ª∂Â¢ûÂº∫Â≠¶‰π†Âíå‰∫∫Á±ªÂÅèÂ•ΩËÆ≠ÁªÉÂÖ∑Â§áÂ§öËΩÆÂØπËØùËÉΩÂäõÂèä‰ΩøÁî®Â§öÁßçÊèí‰ª∂ÁöÑËÉΩÂäõ„ÄÇ
  - Â±ÄÈôêÊÄßÔºöÁî±‰∫éÊ®°ÂûãÂèÇÊï∞ÈáèËæÉÂ∞èÂíåËá™ÂõûÂΩíÁîüÊàêËåÉÂºèÔºåMOSS‰ªçÁÑ∂ÂèØËÉΩÁîüÊàêÂåÖÂê´‰∫ãÂÆûÊÄßÈîôËØØÁöÑËØØÂØºÊÄßÂõûÂ§çÊàñÂåÖÂê´ÂÅèËßÅ/Ê≠ßËßÜÁöÑÊúâÂÆ≥ÂÜÖÂÆπÔºåËØ∑Ë∞®ÊÖéÈâ¥Âà´Âíå‰ΩøÁî®MOSSÁîüÊàêÁöÑÂÜÖÂÆπÔºåËØ∑ÂãøÂ∞ÜMOSSÁîüÊàêÁöÑÊúâÂÆ≥ÂÜÖÂÆπ‰º†Êí≠Ëá≥‰∫íËÅîÁΩë„ÄÇËã•‰∫ßÁîü‰∏çËâØÂêéÊûúÔºåÁî±‰º†Êí≠ËÄÖËá™Ë¥ü„ÄÇ


## ‰∏Ä„ÄÅÂâçË®Ä

Êú¨ÊïôÁ®ã‰∏ªË¶Å‰ªãÁªçÂØπ‰∫é [ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B) Ê®°ÂûãÂü∫‰∫é [LoRA]() ËøõË°åfinetune„ÄÇ

‰ª•[alpaca](https://github.com/tatsu-lab/stanford_alpaca) ‰∏∫‰æã„ÄÇ

Á°¨‰ª∂ÈúÄÊ±Ç

- ÊòæÂç°: ÊòæÂ≠ò >= 16G (ÊúÄÂ•Ω24GÊàñËÄÖ‰ª•‰∏ä)
- ÁéØÂ¢ÉÔºö
  - python>=3.8
  - cuda>=11.6, cupti, cuDNN, TensorRTÁ≠âÊ∑±Â∫¶Â≠¶‰π†ÁéØÂ¢É

## ‰∫å„ÄÅÁéØÂ¢ÉÊê≠Âª∫

### 2.1 ÊûÑÂª∫ÁéØÂ¢É

```s
    $ conda create -n py310_chat python=3.10       # ÂàõÂª∫Êñ∞ÁéØÂ¢É
    $ source activate py310_chat                   # ÊøÄÊ¥ªÁéØÂ¢É
```

### 2.2 ‰∏ãËΩΩ‰ª£Á†Å

```s
    $ git clone https://github.com/mymusise/ChatGLM-Tuning.git
    $ cd ChatGLM-Tuning
```

### 2.3 ÂÆâË£Ö‰æùËµñ

ËøêË°åÂæÆË∞ÉÈúÄË¶Å4.27.1ÁâàÊú¨ÁöÑtransformers„ÄÇÈô§ ChatGLM-6B ÁöÑ‰æùËµñ‰πãÂ§ñÔºåËøòÈúÄË¶ÅÊåâÁÖß‰ª•‰∏ã‰æùËµñ

```s
    $ pip install -r requirements.txt
```

## ‰∏â„ÄÅ‰ΩøÁî®ÊñπÊ≥ï

### 3.1 ËÆ≠ÁªÉÊï∞ÊçÆ‰∏ãËΩΩ

#### 3.1.1 Êï∞ÊçÆÊù•Ê∫ê

1. [alpaca](https://github.com/tatsu-lab/stanford_alpaca)

#### 3.1.2 Êï∞ÊçÆ‰ªãÁªç

Êú¨Á´†‰ΩøÁî® [alpaca](https://github.com/tatsu-lab/stanford_alpaca)‰Ωú‰∏∫Êú¨Ê¨°ÁâπÂÆö‰ªªÂä°ÂæÆË∞ÉÂÆûÈ™åÊï∞ÊçÆ„ÄÇ

> Ê†∑‰æã
```s
[
    {
        "instruction": "Give three tips for staying healthy.",
        "input": "",
        "output": "1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \n2. Exercise regularly to keep your body active and strong. \n3. Get enough sleep and maintain a consistent sleep schedule."
    },...
]
```

- Â≠óÊÆµ
  - instruction: Êåá‰ª§
  - input: ËæìÂÖ•ÔºàÊú¨Êï∞ÊçÆÈõÜÂùá‰∏∫Á©∫Ôºâ
  - output: ËæìÂá∫

#### 3.1.3 ËΩ¨ÂåñalpacaÊï∞ÊçÆÈõÜ‰∏∫jsonl

> ËøêË°å‰ª£Á†Å
```s
    $ python cover_alpaca2jsonl.py  --data_path data/alpaca_data.json  --save_path data/alpaca_data.jsonl 
```

> ÁîüÊàêÊï∞ÊçÆ data/alpaca_data.jsonl 
```s
    {"text": "### Instruction:\nIdentify the odd one out.\n\n### Input:\nTwitter, Instagram, Telegram\n\n### Response:\nTelegram\nEND\n"}
    {"text": "### Instruction:\nExplain why the following fraction is equivalent to 1/4\n\n### Input:\n4/16\n\n### Response:\nThe fraction 4/16 is equivalent to 1/4 because both numerators and denominators are divisible by 4. Dividing both the top and bottom numbers by 4 yields the fraction 1/4.\nEND\n"}
    ...
```
> Ê≥®Ôºötext ‰∏≠ÂåÖÂê´ Instruction„ÄÅInput„ÄÅResponse ‰∏â‰∏™‰ø°ÊÅØ
> ÊãºÊé•Ê†ºÂºè‰∏∫  ### Instruction:\n„ÄêInstructionÂÜÖÂÆπ„Äë\n\n### Input:\n„ÄêInputÂÜÖÂÆπ„Äë\n\n### Response:\n„ÄêResponseÂÜÖÂÆπ„Äë\nEND\n

### 3.2 tokenize_dataset ‰∏ãËΩΩ

```s
    $ python tokenize_dataset_rows.py  --jsonl_path data/alpaca_data.jsonl  --save_path data/alpaca     --max_seq_length 128
```

> --jsonl_path ÂæÆË∞ÉÁöÑÊï∞ÊçÆË∑ØÂæÑ, Ê†ºÂºèjsonl, ÂØπÊØèË°åÁöÑ['context']Âíå['target']Â≠óÊÆµËøõË°åencode
> --save_path ËæìÂá∫Ë∑ØÂæÑ
> --max_seq_length Ê†∑Êú¨ÁöÑÊúÄÂ§ßÈïøÂ∫¶

### 3.3 Ê®°Âûã finetune

ËøêË°å‰ª•‰∏ãÊåá‰ª§ËøõË°åÂæÆË∞ÉÔºö

> lora ÊñπÂºè finetune
```s
    $ python finetune.py \
    --dataset_path data/alpaca \
    --lora_rank 8 \
    --per_device_train_batch_size 6 \
    --gradient_accumulation_steps 1 \
    --max_steps 52000 \
    --save_steps 1000 \
    --save_total_limit 2 \
    --learning_rate 1e-4 \
    --fp16 \
    --remove_unused_columns false \
    --logging_steps 50 \
    --output_dir output
    >>>
    TrainOutput(global_step=1500, training_loss=1.4622032979329427, metrics={'train_runtime': 474.9934, 'train_samples_per_second': 3.158, 'train_steps_per_second': 3.158, 'total_flos': 3781851053211648.0, 'train_loss': 1.4622032979329427, 'epoch': 3.0})
    ...
```

### 3.4 Ê®°ÂûãÊé®ÁêÜ

ËøêË°å‰ª•‰∏ãÊåá‰ª§ËøõË°åÊé®ÁêÜÔºö

> infer.py Êñá‰ª∂
```s
    from modeling_chatglm import ChatGLMForConditionalGeneration
    import torch
    torch.set_default_tensor_type(torch.cuda.HalfTensor)
    model = ChatGLMForConditionalGeneration.from_pretrained("THUDM/chatglm-6b", trust_remote_code=True, device_map='auto')
    from peft import PeftModel
    model = PeftModel.from_pretrained(model, "mymusise/chatGLM-6B-alpaca-lora")
    torch.set_default_tensor_type(torch.cuda.FloatTensor)
    from transformers import AutoTokenizer
    tokenizer = AutoTokenizer.from_pretrained("THUDM/chatglm-6b", trust_remote_code=True)
    from cover_alpaca2jsonl import format_example

    # alpacaÊï∞ÊçÆÈõÜ
    instructions = [
        {'instruction': 'Give three tips for staying healthy.',
        'input': '',
        'output': '1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \n2. Exercise regularly to keep your body active and strong. \n3. Get enough sleep and maintain a consistent sleep schedule.',
        },
        {'instruction': 'What are the three primary colors?',
        'input': '',
        'output': 'The three primary colors are red, blue, and yellow.',
        }
    ]

    with torch.no_grad():
        for idx, item in enumerate(instructions):
            feature = format_example(item)
            input_text = feature['context']
            ids = tokenizer.encode(input_text)
            input_ids = torch.LongTensor([ids])
            out = model.generate(
                input_ids=input_ids,
                max_length=150,
                do_sample=False,
                temperature=0
            )
            out_text = tokenizer.decode(out[0])
            answer = out_text.replace(input_text, "").replace("\nEND", "").strip()
            item['infer_answer'] = answer
            print(out_text)
            print(f"### {idx+1}.Answer:\n", item.get('output'), '\n\n')

```

> ËøêË°å infer.py ËøõË°å Êé®ÁêÜ
```s
    $ python infer.py
    >>>
    Output exceeds the size limit. Open the full output data in a text editor
    Instruction: Give three tips for staying healthy.
    Answer: 1. Eat a balanced diet of fruits, vegetables, lean protein, and whole grains.
    2. Get regular exercise, such as walking, running, or swimming.
    3. Stay hydrated by drinking plenty of water.
    ### 1.Answer:
    1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. 
    2. Exercise regularly to keep your body active and strong. 
    3. Get enough sleep and maintain a consistent sleep schedule. 


    Instruction: What are the three primary colors?
    Answer: The three primary colors are red, blue, and yellow.
    ### 2.Answer:
    The three primary colors are red, blue, and yellow. 
```

## ÂèÇËÄÉ/ÊÑüË∞¢

1. [THUDM/ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B)
2. [mymusise/ChatGLM-Tuning](https://github.com/mymusise/ChatGLM-Tuning) 
3. [‰ªé0Âà∞1Âü∫‰∫éChatGLM-6B‰ΩøÁî®LaRAËøõË°åÂèÇÊï∞È´òÊïàÂæÆË∞É](https://zhuanlan.zhihu.com/p/621793987)
